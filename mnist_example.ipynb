{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a087d24d",
   "metadata": {},
   "source": [
    "Load libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "960c29af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import neural_network_backbone as nnb\n",
    "from sklearn.metrics import accuracy_score \n",
    "from keras.datasets import mnist"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53a50e24",
   "metadata": {},
   "source": [
    "Define macros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "82801831",
   "metadata": {},
   "outputs": [],
   "source": [
    "SILENT = False\n",
    "SEED = 10101\n",
    "EPOCHS = 200\n",
    "LEARNING_RATE = 0.1\n",
    "BATCH_SIZE = 10\n",
    "np.random.seed(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c31ebbe0",
   "metadata": {},
   "source": [
    "Define accuracy helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "04df3d98",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_progress(Y_hat, Y):\n",
    "    cost = get_cost_value(Y_hat, Y)\n",
    "    accuracy = get_accuracy_value(Y_hat, Y)\n",
    "    return \"cost: {:.5f} - accuracy: {:.5f}\".format(cost, accuracy)\n",
    "\n",
    "def one_hot(Y, num_classes):\n",
    "    return np.squeeze(np.eye(num_classes)[Y.reshape(-1)])\n",
    "\n",
    "def convert_prob_into_class(probs):\n",
    "    return np.array([[1. if prob == max(v) else 0. for prob in v] for v in probs]).reshape(probs.shape)\n",
    "\n",
    "def get_accuracy_value(Y_hat, Y):\n",
    "    Y = one_hot(Y, n_outputs)\n",
    "    Y_hat_ = convert_prob_into_class(Y_hat.T)\n",
    "    return accuracy_score(Y, Y_hat_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1023f7ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cost_value(Y_hat, Y, derivative = False):\n",
    "    Y = one_hot(Y, n_outputs)\n",
    "    if not derivative:\n",
    "        eps = 1e-15\n",
    "        Y_hat = np.clip(Y_hat, eps, 1. - eps)\n",
    "        return -np.mean(Y * np.log(Y_hat.T) + (1. - Y) * np.log(1. - Y_hat.T))\n",
    "    else:\n",
    "        return Y_hat.T - Y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "170dbbdc",
   "metadata": {},
   "source": [
    "Load mnist dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c141ad97",
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffe3a4ad",
   "metadata": {},
   "source": [
    "Flatten X values from (60000, 28, 28) to (60000, 784), so it could be easier for Neural Network to operate on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "95d2f63d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 784)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = X_train.reshape(60000, 784)\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcaa2d23",
   "metadata": {},
   "source": [
    "Normalize: mnist pictures are created in gray scale with values from <0, 255> range. We need to normalize it by scaling to <0, 1> range."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "32719d9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train / 255"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b36d3ef5",
   "metadata": {},
   "source": [
    "Define Neural Network Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eacfe097",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_inputs = X_train.shape[1]\n",
    "n_outputs = len(set(y_train))\n",
    "\n",
    "network_layers = [\n",
    "    {\"nodes\": n_inputs},\n",
    "    {\"nodes\": 32, \"activation\": nnb.relu},\n",
    "    {\"nodes\": 64, \"activation\": nnb.relu},\n",
    "    {\"nodes\": 128, \"activation\": nnb.relu},\n",
    "    {\"nodes\": n_outputs, \"activation\": nnb.softmax}\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36e6109f",
   "metadata": {},
   "source": [
    "Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d97236c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 00000 - cost: 0.04255 - accuracy: 0.92940\n",
      "Iteration: 00004 - cost: 0.02062 - accuracy: 0.96583\n",
      "Iteration: 00008 - cost: 0.01361 - accuracy: 0.97902\n",
      "Iteration: 00012 - cost: 0.01181 - accuracy: 0.98242\n",
      "Iteration: 00016 - cost: 0.01000 - accuracy: 0.98600\n",
      "Iteration: 00020 - cost: 0.01004 - accuracy: 0.98678\n",
      "Iteration: 00024 - cost: 0.01071 - accuracy: 0.98635\n",
      "Iteration: 00028 - cost: 0.00803 - accuracy: 0.99190\n",
      "Iteration: 00032 - cost: 0.00889 - accuracy: 0.98943\n",
      "Iteration: 00036 - cost: 0.00905 - accuracy: 0.99032\n",
      "Iteration: 00040 - cost: 0.00837 - accuracy: 0.99317\n",
      "Iteration: 00044 - cost: 0.00831 - accuracy: 0.99277\n",
      "Iteration: 00048 - cost: 0.00880 - accuracy: 0.99210\n",
      "Iteration: 00052 - cost: 0.00904 - accuracy: 0.99227\n",
      "Iteration: 00056 - cost: 0.00820 - accuracy: 0.99365\n",
      "Iteration: 00060 - cost: 0.00844 - accuracy: 0.99358\n",
      "Iteration: 00064 - cost: 0.00823 - accuracy: 0.99383\n",
      "Iteration: 00068 - cost: 0.00823 - accuracy: 0.99388\n",
      "Iteration: 00072 - cost: 0.00827 - accuracy: 0.99410\n",
      "Iteration: 00076 - cost: 0.00829 - accuracy: 0.99407\n",
      "Iteration: 00080 - cost: 0.00829 - accuracy: 0.99393\n",
      "Iteration: 00084 - cost: 0.00832 - accuracy: 0.99400\n",
      "Iteration: 00088 - cost: 0.00837 - accuracy: 0.99405\n",
      "Iteration: 00092 - cost: 0.00836 - accuracy: 0.99395\n",
      "Iteration: 00096 - cost: 0.00836 - accuracy: 0.99410\n",
      "Iteration: 00100 - cost: 0.00836 - accuracy: 0.99412\n",
      "Iteration: 00104 - cost: 0.00837 - accuracy: 0.99415\n",
      "Iteration: 00108 - cost: 0.00837 - accuracy: 0.99425\n",
      "Iteration: 00112 - cost: 0.00839 - accuracy: 0.99417\n",
      "Iteration: 00116 - cost: 0.00849 - accuracy: 0.99428\n",
      "Iteration: 00120 - cost: 0.00853 - accuracy: 0.99428\n",
      "Iteration: 00124 - cost: 0.00854 - accuracy: 0.99427\n",
      "Iteration: 00128 - cost: 0.00855 - accuracy: 0.99433\n",
      "Iteration: 00132 - cost: 0.00859 - accuracy: 0.99428\n",
      "Iteration: 00136 - cost: 0.00862 - accuracy: 0.99428\n",
      "Iteration: 00140 - cost: 0.00863 - accuracy: 0.99430\n",
      "Iteration: 00144 - cost: 0.00865 - accuracy: 0.99432\n",
      "Iteration: 00148 - cost: 0.00867 - accuracy: 0.99437\n",
      "Iteration: 00152 - cost: 0.00868 - accuracy: 0.99435\n",
      "Iteration: 00156 - cost: 0.00869 - accuracy: 0.99438\n",
      "Iteration: 00160 - cost: 0.00871 - accuracy: 0.99435\n",
      "Iteration: 00164 - cost: 0.00873 - accuracy: 0.99433\n",
      "Iteration: 00168 - cost: 0.00873 - accuracy: 0.99438\n",
      "Iteration: 00172 - cost: 0.00874 - accuracy: 0.99438\n",
      "Iteration: 00176 - cost: 0.00875 - accuracy: 0.99445\n",
      "Iteration: 00180 - cost: 0.00877 - accuracy: 0.99445\n",
      "Iteration: 00184 - cost: 0.00878 - accuracy: 0.99448\n",
      "Iteration: 00188 - cost: 0.00880 - accuracy: 0.99450\n",
      "Iteration: 00192 - cost: 0.00881 - accuracy: 0.99450\n",
      "Iteration: 00196 - cost: 0.00884 - accuracy: 0.99450\n"
     ]
    }
   ],
   "source": [
    "nnb.SILENT = SILENT\n",
    "nnb.COST_FUNC = get_cost_value\n",
    "nnb.PROGRESS_FUNC = get_progress\n",
    "params_values = nnb.train(X_train, y_train.reshape((y_train.shape[0], 1)), \n",
    "                          network_layers, EPOCHS, LEARNING_RATE, SEED, BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11463729",
   "metadata": {},
   "source": [
    "Test accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "95ea93c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: cost: 0.02892 - accuracy: 0.97490\n"
     ]
    }
   ],
   "source": [
    "X_test = X_test.reshape(10000, 784)\n",
    "X_test = X_test / 255\n",
    "\n",
    "Y_test_hat, _ = nnb.full_forward_propagation(np.transpose(X_test), params_values, network_layers)\n",
    "print(\"Test set: \" + get_progress(Y_test_hat, np.transpose(y_test.reshape((y_test.shape[0], 1)))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4db40d8d",
   "metadata": {},
   "source": [
    "Save train result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f100f4d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "nnb.save_model(network_layers, params_values, \"output\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da7ed8c9",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
